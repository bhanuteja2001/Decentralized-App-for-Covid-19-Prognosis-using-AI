{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "334a497f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd # Data analysis and manipultion tool\n",
    "import numpy as np # Fundamental package for linear algebra and multidimensional arrays\n",
    "import tensorflow as tf # Deep Learning Tool\n",
    "import os # OS module in Python provides a way of using operating system dependent functionality\n",
    "import cv2 # Library for image processing\n",
    "from sklearn.model_selection import train_test_split # For splitting the data into train and validation set\n",
    "from sklearn.metrics import f1_score\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "d2b572c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "from imutils import build_montages\n",
    "from imutils import paths\n",
    "import random\n",
    "import cv2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6500c34",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "5bdcc64a",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data = pd.read_csv(r\"G:\\PYTHON\\FinalYr_Phase-2\\Meta_data_1.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "905ba70c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>path</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-0.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-10.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-100.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-101.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               path  value\n",
       "0           0    G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-0.png      0\n",
       "1           1    G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-1.png      0\n",
       "2           2   G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-10.png      0\n",
       "3           3  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-100.png      0\n",
       "4           4  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-101.png      0"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "839fe2f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data.drop(Data.columns[0], axis=1, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "98456776",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>value</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-0.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-1.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-10.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-100.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-101.png</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  value\n",
       "0    G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-0.png      0\n",
       "1    G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-1.png      0\n",
       "2   G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-10.png      0\n",
       "3  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-100.png      0\n",
       "4  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-101.png      0"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "42bc7458",
   "metadata": {},
   "outputs": [],
   "source": [
    "Data['split'] = np.random.randn(Data.shape[0], 1)\n",
    "\n",
    "msk = np.random.rand(len(Data)) <= 0.8\n",
    "\n",
    "train = Data[msk]\n",
    "test = Data[~msk]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "cb52af61",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    100\n",
      "1     76\n",
      "Name: value, dtype: int64\n",
      "1    24\n",
      "0    20\n",
      "Name: value, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(train.value.value_counts())\n",
    "print(test.value.value_counts())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "ad01968d",
   "metadata": {},
   "outputs": [],
   "source": [
    "train.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "d032da8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhanu\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>value</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-0.png</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.082360</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-1.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.444722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-100.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.971805</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-102.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.679308</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-103.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.203379</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  value     split\n",
       "0    G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-0.png      0 -1.082360\n",
       "1    G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-1.png      0  0.444722\n",
       "2  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-100.png      0  0.971805\n",
       "3  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-102.png      0  0.679308\n",
       "4  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-103.png      0  0.203379"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train.drop(train.columns[0], axis=1, inplace=True)\n",
    "train.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "915faf28",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = []\n",
    "image_size = 224\n",
    "test_pixel_data = []\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "\n",
    "for i in range(len(train)):\n",
    "    img_array = Image.open(train['path'][i])\n",
    "    new_img_array = np.array(img_array)\n",
    "    if new_img_array.ndim == 2:\n",
    "        new_img_array = cv2.cvtColor(new_img_array, cv2.COLOR_GRAY2BGR)\n",
    "    new_img_array = cv2.resize(new_img_array,(224,224))\n",
    "    #print(i,np.array(new_img_array).shape,train['value'][i])\n",
    "    data.append([new_img_array, train['value'][i]])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "f1ef42fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "test.reset_index(inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "17cd5432",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhanu\\anaconda3\\lib\\site-packages\\pandas\\core\\frame.py:4906: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  return super().drop(\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>path</th>\n",
       "      <th>value</th>\n",
       "      <th>split</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-10.png</td>\n",
       "      <td>0</td>\n",
       "      <td>1.203128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-101.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.001373</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-105.png</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.170708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-108.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.988919</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-110.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.239526</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                path  value     split\n",
       "0   G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-10.png      0  1.203128\n",
       "1  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-101.png      0  0.001373\n",
       "2  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-105.png      0 -0.170708\n",
       "3  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-108.png      0  0.988919\n",
       "4  G:\\PYTHON\\FinalYr_Phase-2\\Cl2\\Chest\\Chest-110.png      0  0.239526"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test.drop(test.columns[0], axis=1, inplace=True)\n",
    "test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "aefadd9b",
   "metadata": {},
   "outputs": [],
   "source": [
    "for i in range(len(test)):\n",
    "    img_array = Image.open(test['path'][i])\n",
    "    new_img_array = np.array(img_array)\n",
    "    if new_img_array.ndim == 2:\n",
    "        new_img_array = cv2.cvtColor(new_img_array, cv2.COLOR_GRAY2BGR)\n",
    "    new_img_array = cv2.resize(new_img_array,(224,224))\n",
    "    test_pixel_data.append(new_img_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "b7b426ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "np.random.shuffle(data)\n",
    "x = []\n",
    "y = []\n",
    "\n",
    "counter = 406\n",
    "count = 0\n",
    "\n",
    "for image in data:\n",
    "    try:\n",
    "        x.append(image[0])\n",
    "        y.append(image[1])\n",
    "    except:\n",
    "        print(count)\n",
    "    count += 1\n",
    "\n",
    "# converting x & y to numpy array as they are list\n",
    "x = np.array(x)\n",
    "y = np.array(y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "19706208",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([0, 1], dtype=int64), array([100,  76], dtype=int64))"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y, return_counts=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a361f18b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    100\n",
       "1     76\n",
       "dtype: int64"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.Series(y).value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "c1810ccc",
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_val, y_train, y_val = train_test_split(x,y,test_size=0.2, random_state = 42,stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "65471f99",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.utils.np_utils import to_categorical\n",
    "y_train = to_categorical(y_train)\n",
    "y_val = to_categorical(y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "a7e864ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 224, 224, 3) (36, 224, 224, 3) (44, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "test_pixel_data = np.array(test_pixel_data)\n",
    "\n",
    "test_pixel_data = test_pixel_data/255\n",
    "\n",
    "print(X_train.shape,X_val.shape,test_pixel_data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "id": "9bbd63a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   rotation_range=15,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='reflect',\n",
    "                                   data_format='channels_last',\n",
    "                                   brightness_range=[0.5, 1.5],\n",
    "                                   featurewise_center=True,\n",
    "                                   featurewise_std_normalization=True)\n",
    "\n",
    "val_datagen = tf.keras.preprocessing.image.ImageDataGenerator(rescale=1.0/255.0)\n",
    "\n",
    "train_generator = train_datagen.flow(X_train,y_train,batch_size=8,shuffle=True)\n",
    "\n",
    "val_generator = val_datagen.flow(X_val,y_val,batch_size=8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ea4410a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "train_datagen = ImageDataGenerator(rescale = 1./255,\n",
    "                                   shear_range = 0.2,\n",
    "                                   zoom_range = 0.2,\n",
    "                                   horizontal_flip = True,\n",
    "                                   width_shift_range=0.2,\n",
    "                                   height_shift_range=0.2,\n",
    "                                   rotation_range=15,\n",
    "                                   vertical_flip=True,\n",
    "                                   fill_mode='reflect',\n",
    "                                   data_format='channels_last',\n",
    "                                   brightness_range=[0.5, 1.5],\n",
    "                                   featurewise_center=True,\n",
    "                                   featurewise_std_normalization=True)\n",
    "\n",
    "test_datagen = ImageDataGenerator(rescale = 1./255)\n",
    "\n",
    "training_set = train_datagen.flow_from_directory('dataset/train',\n",
    "                                                 target_size = (64, 64),\n",
    "                                                 batch_size = 32,\n",
    "                                                 class_mode = 'binary')\n",
    "\n",
    "test_set = test_datagen.flow_from_directory('dataset/validation',\n",
    "                                            target_size = (64, 64),\n",
    "                                            batch_size = 32,\n",
    "                                            class_mode = 'binary')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "a0172d31",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(140, 224, 224, 3) (140, 2) (36, 224, 224, 3)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape,y_train.shape,X_val.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "9a626739",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import MobileNetV2\n",
    "from keras.layers import *\n",
    "from keras.models import Sequential\n",
    "from keras.regularizers import *\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "82ae7887",
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_model():\n",
    "    model = Sequential()\n",
    "\n",
    "    conv_base = MobileNetV2(input_shape=(224,224,3), include_top=False, pooling='max',weights='imagenet')\n",
    "    model.add(conv_base)\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(224, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
    "    model.add(BatchNormalization())\n",
    "    model.add(Dense(128, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
    "    model.add(Dropout(0.5))\n",
    "    model.add(Dense(64, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
    "  # model.add(Dense(2048, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
    "  # model.add(BatchNormalization())\n",
    "  # model.add(Dense(1024, activation='relu', kernel_regularizer=l1_l2(0.01)))\n",
    "  # model.add(BatchNormalization())\n",
    "    model.add(Dense(2, activation='softmax'))\n",
    "    for layer in model.layers:\n",
    "        layer.trainable = True\n",
    " \n",
    "    model.compile(loss='binary_crossentropy', optimizer=Adam(lr=1e-4), metrics=['accuracy',\"Precision\",\"Recall\"])\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "e163f3dd",
   "metadata": {},
   "outputs": [],
   "source": [
    "cbs = [tf.keras.callbacks.ReduceLROnPlateau(monitor='val_acc', factor=0.1, patience=3, min_lr=1e-5, verbose=0),\n",
    "tf.keras.callbacks.EarlyStopping(monitor='val_loss', min_delta=1e-6, patience=10, verbose=1, mode='auto')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "id": "2461a422",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_22\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "mobilenetv2_1.00_224 (Functi (None, 1280)              2257984   \n",
      "_________________________________________________________________\n",
      "batch_normalization_31 (Batc (None, 1280)              5120      \n",
      "_________________________________________________________________\n",
      "dense_44 (Dense)             (None, 224)               286944    \n",
      "_________________________________________________________________\n",
      "batch_normalization_32 (Batc (None, 224)               896       \n",
      "_________________________________________________________________\n",
      "dense_45 (Dense)             (None, 128)               28800     \n",
      "_________________________________________________________________\n",
      "dropout_10 (Dropout)         (None, 128)               0         \n",
      "_________________________________________________________________\n",
      "dense_46 (Dense)             (None, 64)                8256      \n",
      "_________________________________________________________________\n",
      "dense_47 (Dense)             (None, 2)                 130       \n",
      "=================================================================\n",
      "Total params: 2,588,130\n",
      "Trainable params: 2,551,010\n",
      "Non-trainable params: 37,120\n",
      "_________________________________________________________________\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhanu\\anaconda3\\lib\\site-packages\\keras\\optimizer_v2\\optimizer_v2.py:355: UserWarning: The `lr` argument is deprecated, use `learning_rate` instead.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "model = build_model()\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "id": "f8ca0f5a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.keras.callbacks import TensorBoard\n",
    "from time import time\n",
    "Tensorboard = TensorBoard(log_dir=\"G:\\PYTHON\\FinalYr_Phase-2\\logs\\{}\".format(time()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "id": "6ddd2f00",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhanu\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:720: UserWarning: This ImageDataGenerator specifies `featurewise_center`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n",
      "C:\\Users\\Bhanu\\anaconda3\\lib\\site-packages\\keras_preprocessing\\image\\image_data_generator.py:728: UserWarning: This ImageDataGenerator specifies `featurewise_std_normalization`, but it hasn't been fit on any training data. Fit it first by calling `.fit(numpy_data)`.\n",
      "  warnings.warn('This ImageDataGenerator specifies '\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "18/87 [=====>........................] - ETA: 58s - loss: 121.6700 - accuracy: 0.5214 - precision: 0.5214 - recall: 0.5214WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 8700 batches). You may need to use the repeat() function when building your dataset.\n",
      "WARNING:tensorflow:Your input ran out of data; interrupting training. Make sure that your dataset or generator can generate at least `steps_per_epoch * epochs` batches (in this case, 22 batches). You may need to use the repeat() function when building your dataset.\n",
      "87/87 [==============================] - 23s 189ms/step - loss: 121.6700 - accuracy: 0.5214 - precision: 0.5214 - recall: 0.5214 - val_loss: 119.2280 - val_accuracy: 0.9444 - val_precision: 0.9444 - val_recall: 0.9444\n",
      "WARNING:tensorflow:Learning rate reduction is conditioned on metric `val_acc` which is not available. Available metrics are: loss,accuracy,precision,recall,val_loss,val_accuracy,val_precision,val_recall,lr\n",
      "22.7 s ± 0 ns per loop (mean ± std. dev. of 1 run, 1 loop each)\n"
     ]
    }
   ],
   "source": [
    "%%timeit -n1 -r1 \n",
    "with tf.device(\"GPU\"):\n",
    "    model.fit(train_generator,steps_per_epoch=87,epochs=100,validation_data=val_generator,validation_steps=22,callbacks=[cbs])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "id": "0ba08218",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.legend.Legend at 0x27533ffefd0>"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax  = plt.subplots(2,1)\n",
    "\n",
    "#Loss\n",
    "ax[0].plot(model.history.history['loss'], color = 'b', label='Training Loss')\n",
    "ax[0].plot(model.history.history['val_loss'], color = 'r', label='Validation Loss')\n",
    "ax[0].legend()\n",
    "#Accuracy\n",
    "ax[1].plot(model.history.history['accuracy'], color='b', label='Training Accuraccy')\n",
    "ax[1].plot(model.history.history['val_accuracy'], color='r', label='Val Accuracy')\n",
    "ax[1].legend()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "a212f640",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "os.environ['CUDA_VISIBLE_DEVICES'] = '1'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 155,
   "id": "51a247fa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5/5 [==============================] - 1s 129ms/step - loss: 119.2280 - accuracy: 0.9444 - precision: 0.9444 - recall: 0.9444\n"
     ]
    }
   ],
   "source": [
    "pred = model.predict(X_val/255)\n",
    "predictions = np.argmax(pred,axis=1)\n",
    "test_evaluation = model.evaluate(val_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1408ea35",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18/18 [==============================] - 3s 144ms/step - loss: 529.9676 - accuracy: 0.6857 - precision: 0.6857 - recall: 0.6857\n"
     ]
    }
   ],
   "source": [
    "train_evaluation = model.evaluate(train_generator)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "b31f9ce3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Bhanu\\anaconda3\\lib\\site-packages\\keras\\utils\\generic_utils.py:494: CustomMaskWarning: Custom mask layers require a config and must override get_config. When loading, the custom mask layer must be passed to the custom_objects argument.\n",
      "  warnings.warn('Custom mask layers require a config and must override '\n"
     ]
    }
   ],
   "source": [
    "model.save(\"G:\\\\PYTHON\\\\FinalYr_Phase-2\\\\weights\\\\VGG16_CL.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "id": "58f75e7c",
   "metadata": {},
   "outputs": [],
   "source": [
    "Y_VAL = np.array(list(pd.DataFrame(y_val).idxmax(axis=1)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 157,
   "id": "9c3a24d6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[20  0]\n",
      " [ 2 14]]\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0      0.909     1.000     0.952        20\n",
      "           1      1.000     0.875     0.933        16\n",
      "\n",
      "    accuracy                          0.944        36\n",
      "   macro avg      0.955     0.938     0.943        36\n",
      "weighted avg      0.949     0.944     0.944        36\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "print(confusion_matrix(Y_VAL,predictions))\n",
    "print(classification_report(Y_VAL,predictions,digits=3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "9af79b48",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 540x540 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "conf_matrix = confusion_matrix(Y_VAL,predictions)\n",
    "fig, ax = plt.subplots(figsize=(7.5, 7.5))\n",
    "ax.matshow(conf_matrix, cmap=plt.cm.Blues, alpha=0.3)\n",
    "for i in range(conf_matrix.shape[0]):\n",
    "    for j in range(conf_matrix.shape[1]):\n",
    "        ax.text(x=j, y=i,s=conf_matrix[i, j], va='center', ha='center', size='xx-large')\n",
    "\n",
    "plt.xlabel('Predictions', fontsize=18)\n",
    "plt.ylabel('Actuals', fontsize=18)\n",
    "plt.title('Confusion Matrix', fontsize=18)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b1c31916",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "e4549b56",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import load_model\n",
    "model = load_model(\"G:\\\\PYTHON\\\\FinalYr_Phase-2\\\\weights\\\\VGG16_CL.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "202ae592",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Prediction : [0]\n"
     ]
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "# get sample image to test.\n",
    "import numpy as np\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "\n",
    "img_covid = 'G:\\\\PYTHON\\\\Final_year_project\\\\Final\\\\covid_image_data\\\\covid_image_data\\\\Images\\\\COVID\\\\COVID-3.png'\n",
    "img_normal = 'G:\\\\PYTHON\\\\FinalYr_Phase-2\\\\Normal\\\\Normal-99.png'\n",
    "img_test = 'C:\\\\Users\\\\Bhanu\\\\Downloads\\\\sad.jpeg'\n",
    "\n",
    "img_array = Image.open(img_test)\n",
    "new_img_array = np.array(img_array)\n",
    "if new_img_array.ndim == 2:\n",
    "    new_img_array = cv2.cvtColor(new_img_array, cv2.COLOR_GRAY2BGR)\n",
    "new_img_array = cv2.resize(new_img_array,(224,224))\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "dt = []\n",
    "dt.append(new_img_array)\n",
    "X = np.array(dt)\n",
    "X = X/255\n",
    "val = model.predict(X)\n",
    "print(\"Prediction :\",np.argmax(val,axis=1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "ec88aeff",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.argmax(val,axis=1)[0]"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "you",
   "language": "python",
   "name": "you"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
